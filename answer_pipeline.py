from pipeline.iterative import IterativePipeline


actor_models = [
    "gpt-4.1-mini", 
    "gpt-4.1-mini", 
    "gpt-4.1-nano", 
    "gemini-2.0-flash", 
    'nim:meta/llama-4-maverick-17b-128e-instruct', 
    'nim:meta/llama-3.2-11b-vision-instruct',
    'nim:meta/llama-3.2-90b-vision-instruct',
    'nim:meta/llama-4-maverick-17b-128e-instruct',
    'google:gemma-3-27b-it',
    'google:gemma-3-12b-it'
]

critic_models = [
    # 'gemini-2.5-flash-preview-05-20',
    # 'gemini-2.0-flash',
    'gpt-4.1'

]

environment = [
    'html',
    'python'
]


import sys
import os
import json
import random
from datetime import datetime
import uuid

# Import parameters from answer_pipeline
from answer_pipeline import actor_models, critic_models, environment

# Import necessary pipeline components
from pipeline.iterative import IterativePipeline
from pipeline.module import Module, ModuleConfig
from agent import ActorConfig, CriticConfig, VisionCriticConfig, TextCriticConfig
from pipeline.execution import HtmlEnv, HtmlEnvConfig, PythonEnv, PythonEnvConfig
from utils import open_image

def load_questions(jsonl_file='chart_modification.jsonl', done_file='results/result.jsonl'):
    """Load questions from the JSONL file generated by generate_questions.py"""
    questions = []
    done_images = set()
    if os.path.exists(done_file):
        with open(done_file, 'r') as f:
            for line in f:
                data = json.loads(line)
                done_images.add(data['image_path'])


    if os.path.exists(jsonl_file):
        with open(jsonl_file, 'r') as f:
            for line in f:
                data = json.loads(line)
                # Skip if image already processed
                if data['image_path'] in done_images:
                    continue
                questions.append(data)
    return questions

def setup_pipeline(actor_model, critic_model, env_type):
    """Setup pipeline with randomly selected parameters"""
    # Set up environment
    if env_type == 'html':
        env = HtmlEnv(config=HtmlEnvConfig(name="HTML Environment"))
    elif env_type == 'python':
        env = PythonEnv(config=PythonEnvConfig(name="Python Environment"))
    else:
        raise ValueError(f"Unsupported environment: {env_type}")
    
    force_image_path = True
    # Set up module configurations
    actor_config = ActorConfig(name="Chart Actor", model_name=actor_model, code=env_type, image_path=force_image_path, logger='mongodb')
    vision_critic_config = VisionCriticConfig(name="Vision Critic", model_name=critic_model, image_path=force_image_path, logger='mongodb')
    text_critic_config = TextCriticConfig(name="Text Critic", model_name=critic_model, code=env_type, image_path=force_image_path, logger='mongodb')
    # Create critic configuration
    critic_config = CriticConfig(
        name="Chart Critic", 
        vision=vision_critic_config, 
        text=text_critic_config, 
        model_name=critic_model,
        image_path=force_image_path
    )
    
    # Create module and pipeline
    module_config = ModuleConfig(name="Chart Module", actor_config=actor_config, critic_config=critic_config, image_path=force_image_path)
    module = Module(config=module_config)
    
    # Generate unique run name
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_id = str(uuid.uuid4())[:8]
    run_name = f"chart_run_{timestamp}_{run_id}"
    
    pipeline = IterativePipeline(module=module, env=env, run_name=run_name, debug=True)
    
    return pipeline

def save_results(question_data, actor, critic, env_type, results, output_dir="results"):
    """Save the results of processing a question"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    image_id = os.path.basename(question_data["image_path"]).split('.')[0]
    
    result_data = {
        "question": question_data["question"],
        "image_path": question_data["image_path"],
        "actor_model": actor,
        "critic_model": critic,
        "environment": env_type,
        "results": results,
        "timestamp": timestamp
    }
    
    output_file = f"{output_dir}/result_chart.jsonl"
    with open(output_file, 'a') as f:
        f.write(json.dumps(result_data) + '\n')

    return output_file

def main():
    # Load all questions
    questions = load_questions()
    print(f"Loaded {len(questions)} questions")
    
    # Process each question with random parameters
    for i, question_data in enumerate(questions):
        try:
            # Randomly select parameters
            actor = random.choice(actor_models)
            critic = random.choice(critic_models)
            env_type = random.choice(environment)
            
            print(f"\n[{i+1}/{len(questions)}] Processing question with:")
            print(f"  - Actor: {actor}")
            print(f"  - Critic: {critic}")
            print(f"  - Environment: {env_type}")
            print(f"  - Question: {question_data['question']}")
            
            # Setup pipeline
            pipeline = setup_pipeline(actor, critic, env_type)
            
            # Process the question
            image_path = question_data["image_path"]
            task = question_data["question"]
            
            if not os.path.exists(image_path):
                print(f"Image not found: {image_path}, skipping")
                continue
            
            # Run the pipeline
            result = pipeline.act_with_prev_state(request=task, image=image_path)
            
            # Save results
            output_file = save_results(question_data, actor, critic, env_type, result)
            print(f"  - Results saved to: {output_file}")
            
        except Exception as e:
            print(f"Error processing question {i+1}: {str(e)}")
    
    print("\nAll questions processed!")

import concurrent.futures
import threading

def process_question(question_data, idx, total):
    try:
        # Randomly select parameters
        actor = random.choice(actor_models)
        critic = random.choice(critic_models)
        env_type = random.choice(environment)
        
        print_lock = threading.Lock()
        with print_lock:
            print(f"\n[{idx+1}/{total}] Processing question with:")
            print(f"  - Actor: {actor}")
            print(f"  - Critic: {critic}")
            print(f"  - Environment: {env_type}")
            print(f"  - Question: {question_data['question']}")
        
        # Setup pipeline
        pipeline = setup_pipeline(actor, critic, env_type)
        
        # Process the question
        image_path = question_data["image_path"]
        task = question_data["question"]
        
        if not os.path.exists(image_path):
            with print_lock:
                print(f"Image not found: {image_path}, skipping")
            return None
        
        # Run the pipeline
        result = pipeline.act(request=task, image=image_path)
        
        # Save results
        output_file = save_results(question_data, actor, critic, env_type, result)
        with print_lock:
            print(f"  - Results saved to: {output_file}")
        
        return output_file
    except Exception as e:
        with print_lock:
            print(f"Error processing question {idx+1}: {str(e)}")
        return None

def main_threaded(max_workers=2):
    """Multithreaded version of main function to process questions concurrently"""
    # Load all questions
    questions = load_questions()[::-1]
    print(f"Loaded {len(questions)} questions")
    print(f"Using {max_workers} threads")
    
    # Use ThreadPoolExecutor for concurrent execution
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        futures = {executor.submit(process_question, q_data, i, len(questions)): i 
                  for i, q_data in enumerate(questions)}
        
        # Process results as they complete
        completed = 0
        for future in concurrent.futures.as_completed(futures):
            completed += 1
            result = future.result()
            print(f"Progress: {completed}/{len(questions)}", end="\r")
    
    print("\nAll questions processed!")

if __name__ == "__main__":
    # Use main_threaded() instead of main()
    main_threaded()